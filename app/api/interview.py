# app/api/interview.py
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy import func, desc
from typing import List, Optional
from datetime import datetime, timedelta
import json
import random

from app.db.database import get_db
# ğŸ‘‡ --- ä¿®æ”¹ç‚¹ 1: å¯¼å…¥æ–°çš„ã€æ›´å®‰å…¨çš„å‡½æ•° ---
from app.core.security import get_current_active_user
from app.models.user import User # ç¡®ä¿å¯¼å…¥Useræ¨¡å‹ä»¥åœ¨ä¾èµ–ä¸­ä½¿ç”¨
from app.models.interview import Interview, InterviewQuestion, InterviewStatistics, InterviewTrendData
from app.models.question import Question
from app.schemas.interview import *

router = APIRouter()

# ===== é¢è¯•ç®¡ç†æ¥å£ =====

@router.post("/start")
def start_interview(
    interview_data: InterviewCreate,
    # ğŸ‘‡ --- ä¿®æ”¹ç‚¹ 2: ä½¿ç”¨æ–°çš„ä¾èµ– ---
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    å¼€å§‹é¢è¯•
    POST /api/v1/interviews/start
    """
    try:
        config = interview_data.config
        
        # åˆ›å»ºé¢è¯•è®°å½•
        interview = Interview(
            user_id=current_user.id,
            type=interview_data.type,
            position=config.position,
            company_type=config.company_type,
            difficulty=config.difficulty,
            planned_duration=config.duration,
            question_types=config.question_types,
            status="ongoing"
        )
        
        db.add(interview)
        db.flush()  # è·å–interview.id
        
        # ç”Ÿæˆé¢è¯•é¢˜ç›®
        questions = generate_interview_questions(db, config, interview.id)
        interview.total_questions = len(questions)
        
        db.commit()
        db.refresh(interview)
        
        # è¿”å›ç¬¬ä¸€é¢˜
        first_question = questions[0] if questions else None
        
        return {
            "code": 200,
            "data": {
                "interview_id": interview.id,
                "first_question": {
                    "id": first_question.id,
                    "text": first_question.question_text,
                    "type": first_question.question_type or "behavioral",
                    "difficulty": first_question.difficulty or "medium",
                    "hint": get_question_hint(first_question.question_text),
                    "order_index": first_question.order_index
                } if first_question else None,
                "total_questions": len(questions)
            },
            "message": "é¢è¯•å¼€å§‹æˆåŠŸ"
        }
        
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¼€å§‹é¢è¯•å¤±è´¥: {str(e)}"
        )

@router.post("/questions/{question_id}/answer")
def submit_answer(
    question_id: int,
    answer_data: AnswerSubmit,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    æäº¤ç­”æ¡ˆ
    POST /api/v1/interviews/questions/{question_id}/answer
    """
    try:
        # æŸ¥æ‰¾é¢˜ç›®
        question = db.query(InterviewQuestion).filter(
            InterviewQuestion.id == question_id
        ).first()
        
        if not question:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="é¢˜ç›®ä¸å­˜åœ¨"
            )
        
        # éªŒè¯ç”¨æˆ·æƒé™
        interview = db.query(Interview).filter(
            Interview.id == question.interview_id,
            Interview.user_id == current_user.id
        ).first()
        
        if not interview:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒè®¿é—®æ­¤é¢è¯•"
            )
        
        # æ›´æ–°ç­”æ¡ˆ
        question.answer_text = answer_data.answer_text
        question.answer_duration = answer_data.answer_duration
        question.is_skipped = answer_data.is_skipped
        question.hint_used = answer_data.hint_used
        question.answered_at = datetime.utcnow()
        
        # ç”ŸæˆAIè¯„åˆ†å’Œåé¦ˆ
        if not answer_data.is_skipped and answer_data.answer_text:
            feedback = generate_ai_feedback(question.question_text, answer_data.answer_text)
            question.score = feedback["score"]
            question.ai_feedback = json.dumps(feedback)
            question.keyword_match = feedback.get("keyword_match", 0.8)
            question.fluency_score = feedback.get("fluency_score", 0.85)
        
        # æ›´æ–°é¢è¯•è¿›åº¦
        interview.answered_questions += 1
        
        db.commit()
        
        # è¿”å›åé¦ˆ
        if answer_data.is_skipped:
            feedback_response = {
                "score": 0,
                "pros": "å·²è·³è¿‡æ­¤é¢˜",
                "cons": "å»ºè®®å®Œæ•´å›ç­”ä»¥è·å¾—æ›´å¥½çš„è¯„ä¼°",
                "reference": get_reference_answer(question.question_text)
            }
        else:
            feedback_response = json.loads(question.ai_feedback) if question.ai_feedback else {
                "score": 3.5,
                "pros": "å›ç­”åŸºæœ¬å®Œæ•´",
                "cons": "å¯ä»¥æ›´åŠ è¯¦ç»†ä¸€äº›",
                "reference": get_reference_answer(question.question_text)
            }
        
        return {
            "code": 200,
            "data": feedback_response,
            "message": "ç­”æ¡ˆæäº¤æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æäº¤ç­”æ¡ˆå¤±è´¥: {str(e)}"
        )

@router.get("/questions/{question_id}/next")
def get_next_question(
    question_id: int,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¸‹ä¸€é¢˜
    GET /api/v1/interviews/questions/{question_id}/next
    """
    try:
        # æ‰¾å½“å‰é¢˜ç›®
        current_question = db.query(InterviewQuestion).filter(
            InterviewQuestion.id == question_id
        ).first()
        
        if not current_question:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="å½“å‰é¢˜ç›®ä¸å­˜åœ¨"
            )
        
        # éªŒè¯æƒé™
        interview = db.query(Interview).filter(
            Interview.id == current_question.interview_id,
            Interview.user_id == current_user.id
        ).first()
        
        if not interview:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒè®¿é—®æ­¤é¢è¯•"
            )
        
        # æŸ¥æ‰¾ä¸‹ä¸€é¢˜
        next_question = db.query(InterviewQuestion).filter(
            InterviewQuestion.interview_id == current_question.interview_id,
            InterviewQuestion.order_index > current_question.order_index
        ).order_by(InterviewQuestion.order_index).first()
        
        if next_question:
            return {
                "code": 200,
                "data": {
                    "has_next": True,
                    "question": {
                        "id": next_question.id,
                        "text": next_question.question_text,
                        "type": next_question.question_type or "behavioral",
                        "difficulty": next_question.difficulty or "medium",
                        "hint": get_question_hint(next_question.question_text),
                        "order_index": next_question.order_index
                    },
                    "current_progress": next_question.order_index,
                    "total_questions": interview.total_questions
                },
                "message": "è·å–ä¸‹ä¸€é¢˜æˆåŠŸ"
            }
        else:
            return {
                "code": 200,
                "data": {
                    "has_next": False,
                    "question": None,
                    "current_progress": interview.total_questions,
                    "total_questions": interview.total_questions
                },
                "message": "å·²å®Œæˆæ‰€æœ‰é¢˜ç›®"
            }
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä¸‹ä¸€é¢˜å¤±è´¥: {str(e)}"
        )

@router.post("/{interview_id}/complete")
def complete_interview(
    interview_id: int,
    complete_data: InterviewComplete,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    å®Œæˆé¢è¯•
    POST /api/v1/interviews/{interview_id}/complete
    """
    try:
        # æŸ¥æ‰¾é¢è¯•
        interview = db.query(Interview).filter(
            Interview.id == interview_id,
            Interview.user_id == current_user.id
        ).first()
        
        if not interview:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="é¢è¯•ä¸å­˜åœ¨"
            )
        
        # è®¡ç®—é¢è¯•ç»“æœ
        questions = db.query(InterviewQuestion).filter(
            InterviewQuestion.interview_id == interview_id
        ).all()
        
        scores = calculate_interview_scores(questions)
        
        # æ›´æ–°é¢è¯•è®°å½•
        interview.status = "completed"
        interview.finished_at = datetime.utcnow()
        interview.actual_duration = int((datetime.utcnow() - interview.started_at).total_seconds() / 60)
        interview.overall_score = scores["overall"]
        interview.professional_score = scores["professional"]
        interview.expression_score = scores["expression"]
        interview.logic_score = scores["logic"]
        interview.adaptability_score = scores["adaptability"]
        interview.professionalism_score = scores["professionalism"]
        
        # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
        update_user_statistics(db, current_user.id, interview)
        
        # æ›´æ–°è¶‹åŠ¿æ•°æ®
        update_trend_data(db, current_user.id, scores["overall"])
        
        db.commit()
        
        return {
            "code": 200,
            "data": {
                "interview_id": interview.id,
                "overall_score": scores["overall"],
                "duration_minutes": interview.actual_duration,
                "scores": scores,
                "total_questions": interview.total_questions,
                "answered_questions": interview.answered_questions,
                "performance_summary": generate_performance_summary(scores)
            },
            "message": "é¢è¯•å®Œæˆ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å®Œæˆé¢è¯•å¤±è´¥: {str(e)}"
        )

# ===== é¢è¯•æ•°æ®æŸ¥è¯¢æ¥å£ =====

@router.get("/performance")
def get_interview_performance(
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–é¢è¯•è¡¨ç°æ•°æ®
    GET /api/v1/interviews/performance
    
    åŒ¹é…å‰ç«¯ InterviewPerformance.vue çš„æ•°æ®éœ€æ±‚
    """
    try:
        # è·å–ç”¨æˆ·ç»Ÿè®¡
        stats = db.query(InterviewStatistics).filter(
            InterviewStatistics.user_id == current_user.id
        ).first()
        
        if not stats:
            # å¦‚æœæ²¡æœ‰ç»Ÿè®¡æ•°æ®ï¼Œåˆ›å»ºé»˜è®¤æ•°æ®
            stats = create_default_statistics(db, current_user.id)
        
        # è·å–æœ€è¿‘é¢è¯•è®°å½•
        recent_interviews = db.query(Interview).filter(
            Interview.user_id == current_user.id,
            Interview.status == "completed"
        ).order_by(desc(Interview.finished_at)).limit(10).all()
        
        # æ ¼å¼åŒ–å†å²è®°å½•
        recent_records = []
        for interview in recent_interviews:
            recent_records.append({
                "id": interview.id,
                "date": interview.finished_at.strftime("%Y-%m-%d") if interview.finished_at else "",
                "type": interview.type,
                "position": interview.position,
                "duration": f"{interview.actual_duration}åˆ†é’Ÿ" if interview.actual_duration else "æœªçŸ¥",
                "score": round(interview.overall_score or 0)
            })
        
        # æ„é€ èƒ½åŠ›è¯„åˆ†
        ability_scores = {
            "professional": round(stats.avg_professional_score or 0),
            "expression": round(stats.avg_expression_score or 0),
            "logic": round(stats.avg_logic_score or 0),
            "adaptability": round(stats.avg_adaptability_score or 0),
            "professionalism": round(stats.avg_professionalism_score or 0)
        }
        
        # ç»¼åˆè¯„åˆ†
        overall_score = round(stats.avg_overall_score or 0)
        
        performance_data = {
            "overall_score": overall_score,
            "score_level": get_score_level(overall_score),
            "score_comment": get_score_comment(overall_score),
            "better_than": round(stats.better_than_percent or 0),
            "improvement": round(stats.score_improvement or 0),
            "ability_scores": ability_scores,
            "recent_records": recent_records
        }
        
        return {
            "code": 200,
            "data": performance_data,
            "message": "è·å–é¢è¯•è¡¨ç°æˆåŠŸ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–é¢è¯•è¡¨ç°å¤±è´¥: {str(e)}"
        )

@router.get("/trend")
def get_trend_data(
    dimension: str = "overall",
    period: str = "month",
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–è¶‹åŠ¿æ•°æ®
    GET /api/v1/interviews/trend?dimension=overall&period=month
    """
    try:
        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_date = datetime.utcnow()
        if period == "week":
            start_date = end_date - timedelta(days=7)
        elif period == "month":
            start_date = end_date - timedelta(days=30)
        else:
            start_date = end_date - timedelta(days=90)
        
        # æŸ¥è¯¢è¶‹åŠ¿æ•°æ®
        trend_records = db.query(InterviewTrendData).filter(
            InterviewTrendData.user_id == current_user.id,
            InterviewTrendData.record_date >= start_date
        ).order_by(InterviewTrendData.record_date).all()
        
        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        if not trend_records:
            trend_records = generate_mock_trend_data(current_user.id, start_date, end_date)
        
        # æå–æ•°æ®
        dates = []
        scores = []
        
        for record in trend_records:
            dates.append(record.record_date.strftime("%m-%d"))
            
            if dimension == "overall":
                scores.append(round(record.cumulative_avg_score or 0))
            elif dimension == "professional":
                scores.append(round(record.professional_score or 0))
            elif dimension == "expression":
                scores.append(round(record.expression_score or 0))
            elif dimension == "logic":
                scores.append(round(record.logic_score or 0))
            else:
                scores.append(round(record.cumulative_avg_score or 0))
        
        return {
            "code": 200,
            "data": {
                "dates": dates,
                "scores": scores,
                "dimension": dimension
            },
            "message": "è·å–è¶‹åŠ¿æ•°æ®æˆåŠŸ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {str(e)}"
        )

@router.get("/history")
def get_interview_history(
    page: int = 1,
    page_size: int = 10,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–é¢è¯•å†å²
    GET /api/v1/interviews/history?page=1&page_size=10
    """
    try:
        offset = (page - 1) * page_size
        
        # æŸ¥è¯¢é¢è¯•å†å²
        interviews = db.query(Interview).filter(
            Interview.user_id == current_user.id
        ).order_by(desc(Interview.started_at)).offset(offset).limit(page_size).all()
        
        total = db.query(Interview).filter(
            Interview.user_id == current_user.id
        ).count()
        
        # æ ¼å¼åŒ–æ•°æ®
        history_list = []
        for interview in interviews:
            history_list.append({
                "id": interview.id,
                "type": interview.type,
                "position": interview.position,
                "date": interview.started_at.strftime("%Y-%m-%d %H:%M"),
                "duration": f"{interview.actual_duration or interview.planned_duration}åˆ†é’Ÿ",
                "score": round(interview.overall_score or 0),
                "status": interview.status
            })
        
        return {
            "code": 200,
            "data": {
                "list": history_list,
                "total": total,
                "page": page,
                "page_size": page_size
            },
            "message": "è·å–é¢è¯•å†å²æˆåŠŸ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–é¢è¯•å†å²å¤±è´¥: {str(e)}"
        )

# ===== è¾…åŠ©å‡½æ•° =====

def generate_interview_questions(db: Session, config: InterviewConfig, interview_id: int):
    """ç”Ÿæˆé¢è¯•é¢˜ç›®"""
    questions = []
    
    # ä»çŸ¥è¯†åº“è·å–é¢˜ç›®
    query = db.query(Question).filter(Question.is_active == True)
    
    # æ ¹æ®å²—ä½ç­›é€‰
    if config.position == "frontend":
        query = query.filter(Question.category.in_(["å‰ç«¯å¼€å‘", "ç®—æ³•æ•°æ®ç»“æ„"]))
    elif config.position == "backend":
        query = query.filter(Question.category.in_(["åç«¯å¼€å‘", "ç®—æ³•æ•°æ®ç»“æ„"]))
    
    available_questions = query.all()
    
    # éšæœºé€‰æ‹©é¢˜ç›®ï¼ˆç®€åŒ–ç‰ˆï¼‰
    selected_questions = random.sample(available_questions, min(5, len(available_questions)))
    
    # æ·»åŠ é€šç”¨é—®é¢˜
    common_questions = [
        "è¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»",
        "ä»‹ç»ä¸€ä¸ªä½ è´Ÿè´£çš„é¡¹ç›®",
        "ä½ çš„èŒä¸šè§„åˆ’æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    # åˆ›å»ºé¢è¯•é¢˜ç›®è®°å½•
    for i, q in enumerate(selected_questions[:3]):
        interview_question = InterviewQuestion(
            interview_id=interview_id,
            question_id=q.id,
            question_text=q.title,
            question_type=q.category,
            difficulty=q.difficulty,
            order_index=i + 1
        )
        questions.append(interview_question)
    
    # æ·»åŠ é€šç”¨é—®é¢˜
    for i, q_text in enumerate(common_questions[:2]):
        interview_question = InterviewQuestion(
            interview_id=interview_id,
            question_text=q_text,
            question_type="behavioral",
            difficulty="medium",
            order_index=len(questions) + i + 1
        )
        questions.append(interview_question)
    
    # æ‰¹é‡ä¿å­˜
    for q in questions:
        db.add(q)
    
    return questions

def generate_ai_feedback(question: str, answer: str):
    """ç”ŸæˆAIåé¦ˆï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # è¿™é‡Œæ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥è°ƒç”¨AIæ¥å£
    base_score = random.uniform(3.0, 4.5)
    
    feedback = {
        "score": round(base_score, 1),
        "pros": "å›ç­”ç»“æ„æ¸…æ™°ï¼Œè¡¨è¾¾æµç•…ï¼Œé‡ç‚¹çªå‡ºã€‚",
        "cons": "å¯ä»¥å¢åŠ ä¸€äº›å…·ä½“çš„æ¡ˆä¾‹æ¥æ”¯æ’‘è§‚ç‚¹ï¼Œè®©å›ç­”æ›´æœ‰è¯´æœåŠ›ã€‚",
        "reference": "å‚è€ƒç­”æ¡ˆï¼šå»ºè®®ä»å…·ä½“èƒŒæ™¯å¼€å§‹ï¼Œç„¶åä»‹ç»è§£å†³æ–¹æ¡ˆå’Œç»“æœã€‚",
        "keyword_match": random.uniform(0.7, 0.9),
        "fluency_score": random.uniform(0.8, 0.95)
    }
    
    return feedback

def calculate_interview_scores(questions):
    """è®¡ç®—é¢è¯•å„é¡¹è¯„åˆ†"""
    total_score = 0
    count = 0
    
    for q in questions:
        if q.score is not None:
            total_score += q.score
            count += 1
    
    overall = (total_score / count * 20) if count > 0 else 75  # è½¬æ¢ä¸º100åˆ†åˆ¶
    
    # ç”Ÿæˆå„é¡¹è¯„åˆ†ï¼ˆåŸºäºæ•´ä½“è¯„åˆ†çš„æ³¢åŠ¨ï¼‰
    scores = {
        "overall": round(overall, 1),
        "professional": round(overall + random.uniform(-5, 5), 1),
        "expression": round(overall + random.uniform(-3, 3), 1),
        "logic": round(overall + random.uniform(-4, 4), 1),
        "adaptability": round(overall + random.uniform(-6, 6), 1),
        "professionalism": round(overall + random.uniform(-2, 2), 1)
    }
    
    # ç¡®ä¿è¯„åˆ†åœ¨åˆç†èŒƒå›´å†…
    for key in scores:
        scores[key] = max(0, min(100, scores[key]))
    
    return scores

def update_user_statistics(db: Session, user_id: int, interview: Interview):
    """æ›´æ–°ç”¨æˆ·ç»Ÿè®¡æ•°æ®"""
    stats = db.query(InterviewStatistics).filter(
        InterviewStatistics.user_id == user_id
    ).first()
    
    if not stats:
        stats = InterviewStatistics(user_id=user_id)
        db.add(stats)
    
    # æ›´æ–°ç»Ÿè®¡
    stats.total_interviews += 1
    if interview.type == "practice":
        stats.total_practice += 1
    else:
        stats.total_simulation += 1
    
    stats.total_time_minutes += interview.actual_duration or 0
    
    # æ›´æ–°å¹³å‡åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    if interview.overall_score:
        current_avg = stats.avg_overall_score or 0
        total_interviews = stats.total_interviews
        stats.avg_overall_score = (current_avg * (total_interviews - 1) + interview.overall_score) / total_interviews
        
        # æ›´æ–°å…¶ä»–å¹³å‡åˆ†
        stats.avg_professional_score = interview.professional_score
        stats.avg_expression_score = interview.expression_score
        stats.avg_logic_score = interview.logic_score
        stats.avg_adaptability_score = interview.adaptability_score
        stats.avg_professionalism_score = interview.professionalism_score
    
    # æ›´æ–°æ’åï¼ˆæ¨¡æ‹Ÿï¼‰
    stats.better_than_percent = min(95, 60 + stats.total_interviews * 2)
    stats.score_improvement = random.uniform(8, 15)
    
    stats.last_interview_date = datetime.utcnow()

def update_trend_data(db: Session, user_id: int, score: float):
    """æ›´æ–°è¶‹åŠ¿æ•°æ®"""
    today = datetime.utcnow().date()
    
    trend = db.query(InterviewTrendData).filter(
        InterviewTrendData.user_id == user_id,
        func.date(InterviewTrendData.record_date) == today
    ).first()
    
    if not trend:
        trend = InterviewTrendData(
            user_id=user_id,
            record_date=datetime.utcnow(),
            daily_score=score,
            interviews_count=1,
            cumulative_avg_score=score
        )
        db.add(trend)
    else:
        # æ›´æ–°å½“æ—¥æ•°æ®
        trend.interviews_count += 1
        trend.daily_score = (trend.daily_score * (trend.interviews_count - 1) + score) / trend.interviews_count
        trend.cumulative_avg_score = score  # ç®€åŒ–å¤„ç†

# å…¶ä»–è¾…åŠ©å‡½æ•°...
def get_question_hint(question_text: str) -> str:
    """è·å–é¢˜ç›®æç¤º"""
    hints = {
        "è‡ªæˆ‘ä»‹ç»": "å»ºè®®æŒ‰ç…§'ä¸ªäººä¿¡æ¯-æ•™è‚²èƒŒæ™¯-é¡¹ç›®ç»éªŒ-æŠ€èƒ½ç‰¹é•¿-èŒä¸šè§„åˆ’'çš„ç»“æ„æ¥ç»„ç»‡å›ç­”ã€‚",
        "é¡¹ç›®": "ä½¿ç”¨STARæ³•åˆ™ï¼šSituationï¼ˆæƒ…å¢ƒï¼‰ã€Taskï¼ˆä»»åŠ¡ï¼‰ã€Actionï¼ˆè¡ŒåŠ¨ï¼‰ã€Resultï¼ˆç»“æœï¼‰ã€‚",
        "Vue": "å¯ä»¥ä»æŠ€æœ¯ç‰¹ç‚¹ã€ä½¿ç”¨åœºæ™¯ã€æ€§èƒ½ä¼˜åŒ–ç­‰è§’åº¦æ¥å›ç­”ã€‚"
    }
    
    for key, hint in hints.items():
        if key in question_text:
            return hint
    
    return "å»ºè®®ç»“æ„åŒ–è¡¨è¾¾ï¼Œé€»è¾‘æ¸…æ™°ï¼Œç»“åˆå…·ä½“ä¾‹å­ã€‚"

def get_reference_answer(question_text: str) -> str:
    """è·å–å‚è€ƒç­”æ¡ˆ"""
    return "å‚è€ƒç­”æ¡ˆï¼šå»ºè®®ä»èƒŒæ™¯ä»‹ç»å¼€å§‹ï¼Œç„¶åè¯¦ç»†è¯´æ˜è§£å†³æ–¹æ¡ˆå’Œæœ€ç»ˆç»“æœï¼Œå±•ç°ä¸ªäººèƒ½åŠ›å’Œæˆé•¿ã€‚"

def get_score_level(score: int) -> str:
    """è·å–è¯„åˆ†ç­‰çº§"""
    if score >= 90:
        return "ä¼˜ç§€"
    elif score >= 80:
        return "è‰¯å¥½"
    elif score >= 70:
        return "ä¸­ç­‰"
    elif score >= 60:
        return "åŠæ ¼"
    else:
        return "å¾…æå‡"

def get_score_comment(score: int) -> str:
    """è·å–è¯„åˆ†è¯„è¯­"""
    if score >= 90:
        return "æ‚¨çš„é¢è¯•è¡¨ç°éå¸¸å‡ºè‰²ï¼Œä¿æŒè¿™ä¸ªçŠ¶æ€ï¼"
    elif score >= 80:
        return "è¡¨ç°è‰¯å¥½ï¼Œè¿˜æœ‰ä¸€äº›ç»†èŠ‚å¯ä»¥ä¼˜åŒ–"
    elif score >= 70:
        return "åŸºç¡€æ‰å®ï¼Œéœ€è¦åŠ å¼ºæŸäº›æ–¹é¢çš„è®­ç»ƒ"
    else:
        return "å»ºè®®å¤šåŠ ç»ƒä¹ ï¼Œé‡ç‚¹æå‡è–„å¼±ç¯èŠ‚"

def create_default_statistics(db: Session, user_id: int):
    """åˆ›å»ºé»˜è®¤ç»Ÿè®¡æ•°æ®"""
    stats = InterviewStatistics(
        user_id=user_id,
        total_interviews=0,
        avg_overall_score=0,
        better_than_percent=0,
        score_improvement=0
    )
    db.add(stats)
    db.commit()
    return stats

def generate_mock_trend_data(user_id: int, start_date: datetime, end_date: datetime):
    """ç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®"""
    data = []
    current_date = start_date
    base_score = 75
    
    while current_date <= end_date:
        score = base_score + random.uniform(-5, 10)
        base_score = min(95, base_score + 0.2)  # é€æ¸æå‡
        
        data.append(type('MockTrendData', (), {
            'record_date': current_date,
            'cumulative_avg_score': score,
            'professional_score': score + random.uniform(-3, 3),
            'expression_score': score + random.uniform(-2, 2),
            'logic_score': score + random.uniform(-4, 4)
        }))
        
        current_date += timedelta(days=1)
    
    return data

def generate_performance_summary(scores: dict) -> str:
    """ç”Ÿæˆè¡¨ç°æ€»ç»“"""
    overall = scores["overall"]
    if overall >= 85:
        return "æ•´ä½“è¡¨ç°ä¼˜ç§€ï¼Œå„é¡¹èƒ½åŠ›å‡è¡¡å‘å±•ï¼Œç»§ç»­ä¿æŒï¼"
    elif overall >= 75:
        return "è¡¨ç°è‰¯å¥½ï¼Œåœ¨æŸäº›æ–¹é¢è¿˜æœ‰æå‡ç©ºé—´ã€‚"
    else:
        return "åŸºç¡€æ‰å®ï¼Œå»ºè®®åŠ å¼ºç»ƒä¹ æå‡é¢è¯•æŠ€å·§ã€‚"